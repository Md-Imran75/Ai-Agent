import { AssemblyAI } from "assemblyai";
import mic from "mic";
import dotenv from "dotenv";
import { generateAIResponseForText } from "./testAiResponse.js";
import { generateSpeechForTest, playAIResponseForTest } from "./testtospeechfortest.js";

dotenv.config();
const ASSEMBLYAI_API_KEY = process.env.ASSEMBLYAI_API_KEY;

let client;
let transcriber;
let micInstance;
let isProcessing = false;
let isListening = true;
let silenceTimer;
let fullTranscript = "";
let lastSpeechTime = Date.now();

// ðŸŽ™ **Start AI Listening**
const startRealTimeTranscription = async () => {
  console.log("ðŸŽ™ AI is now listening...");

  client = new AssemblyAI({ apiKey: ASSEMBLYAI_API_KEY });
  transcriber = client.realtime.transcriber({ sampleRate: 16000 });

  transcriber.on("open", ({ sessionId }) => {
    console.log(`âœ… WebSocket connected! Session ID: ${sessionId}`);
    startMic();
  });

  transcriber.on("error", (error) => {
    console.error("âŒ Transcription error:", error);
    restartService();
  });

  transcriber.on("close", () => {
    console.log("ðŸ”„ Reconnecting transcription service...");
    restartService();
  });

  transcriber.on("transcript", async (transcript) => {
    if (!transcript.text || transcript.text.trim().length === 0) {
      console.log("âš ï¸ No meaningful text detected.");
      return;
    }

    console.log(`ðŸ“ Partial Transcription: ${transcript.text}`);

    fullTranscript = transcript.text;
    lastSpeechTime = Date.now();

    clearTimeout(silenceTimer);
    silenceTimer = setTimeout(() => {
      console.log("â³ Processing transcript after delay...");
      processTranscript();
    }, 4000);
  });

  console.log("ðŸŒ Connecting to transcript service...");
  await transcriber.connect();
};

// ðŸŽ¤ **Start Microphone**
const startMic = () => {
  if (!isListening) return;

  console.log("ðŸŽ¤ Starting microphone...");
  micInstance = mic({
    rate: "16000",
    channels: "1",
    debug: true,
    device: "WO Mic Device", // Ensure your mic name is correct
  });

  const micStream = micInstance.getAudioStream();
  micInstance.start();
  console.log("ðŸŽ™ Microphone started!");

  micStream.on("data", (data) => {
    if (!transcriber || !transcriber.isConnected) return;
    
    try {
      transcriber.sendAudio(data);
    } catch (err) {
      console.error("âŒ Error sending audio to WebSocket:", err.message);
      restartService();
    }
  });

  micStream.on("error", (err) => {
    console.error("âŒ Microphone error:", err);
    restartService();
  });

  micStream.on("end", () => {
    console.log("ðŸ›‘ Microphone stream ended. Restarting...");
    restartService();
  });

  // âœ… **Silence Detection**
  clearTimeout(silenceTimer);
  silenceTimer = setInterval(() => {
    if (Date.now() - lastSpeechTime > 5000 && fullTranscript.trim().length > 0) {
      console.log("ðŸ›‘ Silence detected. Processing transcript...");
      processTranscript();
    }
  }, 500);
};

// ðŸ”„ **Restart Service if WebSocket Fails**
const restartService = async () => {
  console.log("ðŸ”„ Restarting AI Service...");
  try {
    if (micInstance) micInstance.stop();
    if (transcriber) await transcriber.close();
  } catch (err) {
    console.error("âŒ Error closing resources:", err.message);
  }
  setTimeout(startRealTimeTranscription, 3000);
};

// ðŸ“œ **Process Speech and Generate AI Response**
const processTranscript = async () => {
  if (!fullTranscript.trim() || isProcessing) return;

  isProcessing = true;
  isListening = false;
  console.log(`ðŸ“ Final Transcribed Text: ${fullTranscript.trim()}`);

  fullTranscript = fullTranscript
    .split(" ")
    .filter((word, index, arr) => index === 0 || word !== arr[index - 1])
    .join(" ");

  const aiResponse = await generateAIResponseForText(fullTranscript.trim());
  console.log(`ðŸ¤– AI Response: ${aiResponse}`);

  fullTranscript = "";

  const speechPath = await generateSpeechForTest(aiResponse);

  await playAIResponseForTest(speechPath, () => {
    console.log("ðŸŽ™ Restarting microphone...");
    isProcessing = false;
    isListening = true;
    startMic();
  });
};

// ðŸ›‘ **Graceful Exit Handling**
process.on("SIGINT", async function () {
  console.log("\nðŸ›‘ Stopping microphone...");
  if (micInstance) micInstance.stop();
  console.log("ðŸ”Œ Closing transcription...");
  if (transcriber) await transcriber.close();
  console.log("ðŸ‘‹ Exiting AI.");
  process.exit();
});

// ðŸŽ§ **Start AI Listening**
startRealTimeTranscription();
